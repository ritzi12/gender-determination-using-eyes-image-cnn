{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DPhi_Datathon_DLBootcamp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOoIml4fb2Sx4RRyvVjacor",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritzi12/gender-determination-using-eyes-image-cnn/blob/main/DPhi_Datathon_DLBootcamp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Glayupdg4aOl"
      },
      "source": [
        "# **Gender Determination by Morphometry of Eyes**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FwyuRBjllPj"
      },
      "source": [
        "\n",
        "\n",
        "> ##### **AUTHOR** : RITIKA GUPTA\n",
        "> ##### *DPhi Profile Link:* https://dphi.tech/profile/ritika12/\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPp_rFv0HCkN"
      },
      "source": [
        "## Download the images\n",
        "\n",
        "\n",
        "We can use **GoogleDriveDownloader** form **google_drive_downloader** library in Python to download the shared files from the shared Google drive link: https://drive.google.com/file/d/1f7uslI-ZHidriQFZR966_aILjlkgDN76/view?usp=sharing\n",
        "\n",
        "The file id in the above link is: **1f7uslI-ZHidriQFZR966_aILjlkgDN76**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WAFWh2BHJDZ",
        "outputId": "b94f015d-d5d8-47cc-eb77-ee6b8f023044"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1f7uslI-ZHidriQFZR966_aILjlkgDN76',\n",
        "                                    dest_path='content/eye_gender_data.zip',\n",
        "                                    unzip=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1f7uslI-ZHidriQFZR966_aILjlkgDN76 into content/eye_gender_data.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV-nUSQgHTnZ"
      },
      "source": [
        "We have all the files from the shared Google drive link downloaded in the colab environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzyVNI3BHdTn"
      },
      "source": [
        "## Loading Libraries\n",
        "All Python capabilities are not loaded to our working environment by default (even they are already installed in your system). So, we import each and every library that we want to use.\n",
        "\n",
        "We chose alias names for our libraries for the sake of our convenience (numpy --> np and pandas --> pd, tensorlow --> tf).\n",
        "\n",
        "Note: You can import all the libraries that you think will be required or can import it as you go along."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW_3T2d1HVTc"
      },
      "source": [
        "import pandas as pd                                     # Data analysis and manipulation tool\n",
        "import numpy as np                                      # Fundamental package for linear algebra and multidimensional arrays\n",
        "import tensorflow as tf                                 # Deep Learning Tool\n",
        "import os                                               # OS module in Python provides a way of using operating system dependent functionality\n",
        "import cv2                                              # Library for image processing\n",
        "from sklearn.model_selection import train_test_split    # For splitting the data into train and validation set\n",
        "from sklearn.metrics import f1_score\n",
        "from google.colab.patches import cv2_imshow             #To display images in colab for jupyter use cv2.imshow() method\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard      #Tensor Flow Visual Dashboard\n",
        "import datetime                                         #Required to create log directory based on timestamp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5dADcjSPZsA",
        "outputId": "a9b1d7d1-ac91-484d-fc1f-d2fbba590702"
      },
      "source": [
        "#Check GPUs \n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE6EtiSULT0f"
      },
      "source": [
        "## Loading and preparing training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "xr57cFw7LUYL",
        "outputId": "d790f4c7-f967-4864-865b-7538bffcf272"
      },
      "source": [
        "labels = pd.read_csv(\"/content/content/eye_gender_data/Training_set.csv\")   # loading the labels\n",
        "file_paths = [[fname, '/content/content/eye_gender_data/train/' + fname] for fname in labels['filename']]\n",
        "images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
        "train_data = pd.merge(images, labels, how = 'inner', on = 'filename')\n",
        "\n",
        "\n",
        "#Checking train images\n",
        "imgg=cv2.imread(train_data['filepaths'][1], cv2.IMREAD_COLOR)\n",
        "print(\"Image Shape:\",imgg.shape)\n",
        "cv2_imshow(imgg)\n",
        "#cv2.waitKey(0)\n",
        "#cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Shape: (58, 58, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=58x58 at 0x7FB430631B10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pmff9hQPoB9"
      },
      "source": [
        "data = []     # initialize an empty numpy array\n",
        "image_size = 100      # image size taken is 100 here. one can take other size too\n",
        "train_images=np.asarray(np.zeros((len(train_data),image_size,image_size)))\n",
        "for i in range(len(train_data)):\n",
        "  \n",
        "  img_array = cv2.imread(train_data['filepaths'][i], cv2.IMREAD_GRAYSCALE)   # converting the image to gray scale\n",
        "\n",
        "  new_img_array = cv2.resize(img_array, (image_size, image_size))      # resizing the image array\n",
        "  train_images[i]=new_img_array\n",
        "  data.append([new_img_array, train_data['label'][i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "Ty9XL2R-MnBn",
        "outputId": "40885002-b67a-45c7-df09-67306acfc094"
      },
      "source": [
        "#Check image after greyscale conversion & resizing\n",
        "cv2_imshow(data[1][0])\n",
        "data[0][0].shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100 at 0x7FB499EFFE90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx0sPgpf4EXg"
      },
      "source": [
        "## Data Pre-processing\n",
        "It is necessary to bring all the images in the same shape and size, also convert them to their pixel values because all machine learning or deep learning models accepts only the numerical data. Also we need to convert all the labels from categorical to numerical values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC8MaKXP4G1g",
        "outputId": "cde38eb4-1016-4118-84ca-727d09774856"
      },
      "source": [
        "train_labels= np.asarray([0 if x=='male' else 1 for x in labels['label']]) #converting categorical labels to numerical labels\n",
        "label_name=['male','female']          #creating label name array based on numeric label assigned\n",
        "\n",
        "#train_label_df=pd.DataFrame(train_labels,columns=['label'])\n",
        "#print(train_label_df.head())\n",
        "\n",
        "#Reshape\n",
        "train_images=train_images.reshape(len(train_data),image_size,image_size,1)\n",
        "print(train_images.shape)\n",
        "#Normalize\n",
        "train_images=train_images/255.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9220, 100, 100, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIk4LnjEDVsc"
      },
      "source": [
        "## Building Model & Hyperparameter tuning\n",
        "Now we are finally ready, and we can train the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tm21OqGDYxL"
      },
      "source": [
        "\n",
        "INPUT_SHAPE=(image_size,image_size,1)\n",
        "np.random.seed(seed=120)\n",
        "\n",
        "#Define Model\n",
        "def cnn_model():\n",
        "    # define sequential model\n",
        "  model = tf.keras.models.Sequential()\n",
        "  # define conv-pool layers - set 1\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(2, 2), strides=(1, 1),\n",
        "  activation='relu', padding='same', input_shape=INPUT_SHAPE))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  # define conv-pool layers - set 2\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(2, 2), strides=(1, 1),\n",
        "  activation='relu', padding='same', input_shape=INPUT_SHAPE))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        " # define conv-pool layers - set 3\n",
        "  model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), \n",
        "  activation='relu', padding='same', input_shape=INPUT_SHAPE))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  # define conv-pool layers - set 3\n",
        "  model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(9, 9), strides=(1, 1), \n",
        "  activation='relu', padding='same', input_shape=INPUT_SHAPE))\n",
        " \n",
        "  # add flatten layer\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "  # add dense layers with some dropout\n",
        "  model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "  model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "  model.add(tf.keras.layers.BatchNormalization(axis=1))\n",
        "  # add output layer\n",
        "  model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmN6LJbqSTE_",
        "outputId": "3204eda0-bc97-4c1d-bcb5-64a7c7510465"
      },
      "source": [
        "#Create Model\n",
        "model=cnn_model()\n",
        "# view model layers\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 100, 64)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 50, 50, 128)       32896     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 25, 25, 256)       819456    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 256)       5308672   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 36864)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               9437440   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 15,666,114\n",
            "Trainable params: 15,665,602\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm3PRX5VSgb_"
      },
      "source": [
        "# compile model\n",
        "model.compile(optimizer='adam',\n",
        "loss='sparse_categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "# Define Call Backs\n",
        "EPOCHS = 100\n",
        "#EarlyStop Callbacks\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,\n",
        "restore_best_weights=True,\n",
        "verbose=1)\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ \n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "#Tensorboard\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "%load_ext tensorboard\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCN0TcLiTX5S",
        "outputId": "cad3eee2-ac3e-4ebf-cd90-167c5ff942c4"
      },
      "source": [
        "history = model.fit(train_images, train_labels,\n",
        "batch_size=32,\n",
        "callbacks=[es_callback,tensorboard_callback],\n",
        "validation_split=0.1, epochs=EPOCHS,\n",
        "verbose=1)\n",
        "\n",
        "# Fetch Minimum Loss stored in  model history\n",
        "loss = np.min(history.history['val_loss'])\n",
        "print(\"Minimum Loss\", loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "260/260 [==============================] - 47s 54ms/step - loss: 0.7912 - accuracy: 0.5263 - val_loss: 0.6813 - val_accuracy: 0.5542\n",
            "Epoch 2/100\n",
            "260/260 [==============================] - 12s 46ms/step - loss: 0.7210 - accuracy: 0.5365 - val_loss: 0.6915 - val_accuracy: 0.5488\n",
            "Epoch 3/100\n",
            "260/260 [==============================] - 12s 46ms/step - loss: 0.6889 - accuracy: 0.5512 - val_loss: 0.7509 - val_accuracy: 0.5488\n",
            "Epoch 4/100\n",
            "260/260 [==============================] - 12s 47ms/step - loss: 0.6824 - accuracy: 0.5717 - val_loss: 0.7818 - val_accuracy: 0.5488\n",
            "Epoch 5/100\n",
            "260/260 [==============================] - 12s 47ms/step - loss: 0.6661 - accuracy: 0.5985 - val_loss: 1.0862 - val_accuracy: 0.5488\n",
            "Epoch 6/100\n",
            "260/260 [==============================] - 12s 46ms/step - loss: 0.5817 - accuracy: 0.6970 - val_loss: 0.6953 - val_accuracy: 0.6041\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "Minimum Loss 0.6812728643417358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eW41nTgY4At"
      },
      "source": [
        "## Evaluation of Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QAyWsJ8dZDhn",
        "outputId": "e8c64fad-5f8c-4095-a37f-9238070daa73"
      },
      "source": [
        "%tensorboard --logdir logs/fit        #Magic Command Used to call TensorBoard \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCn-xcpUA6sv"
      },
      "source": [
        "### Save Model\n",
        "\n",
        "We will save our trained model in the directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fBkygxjxcwwJ"
      },
      "source": [
        "#Make Directory to save Model\n",
        "!mkdir -p saved_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0I15tvCA_d0"
      },
      "source": [
        "model.save('saved_model/cnn_model_3')\n",
        "!ls saved_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dXli_FVy_QGS",
        "outputId": "63f0eafa-2878-4b1b-c9cc-ec0146dbffbc"
      },
      "source": [
        "#Loading the model from saved location\n",
        "loaded_model = tf.keras.models.load_model('saved_model/cnn_model_3')\n",
        "\n",
        "# Check its architecture\n",
        "loaded_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 100, 100, 64)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 50, 50, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 50, 50, 128)       32896     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 25, 25, 256)       819456    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 256)       5308672   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 36864)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               9437440   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 15,666,114\n",
            "Trainable params: 15,665,602\n",
            "Non-trainable params: 512\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXR3v0NhcjMv"
      },
      "source": [
        "## Predict The Output For Testing Dataset 😅\n",
        "We have trained our model, evaluated it and now finally we will predict the output/target for the testing data (i.e. Test.csv)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tWhka4wBm7a"
      },
      "source": [
        "#### Load Test Set\n",
        "Load the test data on which final submission is to be made.\n",
        "\n",
        "Note: The Test Set doesn't contain labels only filenames.The predictions will be verified once the 'submission.csv' is uploaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SV1VFim2cik-"
      },
      "source": [
        "test_labels = pd.read_csv(\"/content/content/eye_gender_data/Testing_set.csv\")   # loading the test labels\n",
        "file_paths = [[fname, '/content/content/eye_gender_data/test/' + fname] for fname in test_labels['filename']]\n",
        "images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
        "test_data = pd.merge(images, labels, how = 'inner', on = 'filename')\n",
        "\n",
        "\n",
        "image_size = 100      # image size taken is 100 here, one can take other size too\n",
        "test_images=np.asarray(np.zeros((len(test_data),image_size,image_size))) #initialize numpy array\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "  img_array = cv2.imread(test_data['filepaths'][i], cv2.IMREAD_GRAYSCALE)   # converting the image to gray scale\n",
        "  new_img_array = cv2.resize(img_array, (image_size, image_size))      # resizing the image array\n",
        "  test_images[i]=new_img_array\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nRlbn2eadrwd",
        "outputId": "a85b6a43-636c-47d8-cd30-d2521f82142a"
      },
      "source": [
        "#Check image after greyscale conversion & resizing\n",
        "cv2_imshow(test_images[0])\n",
        "print(\"Test Images shape:\\n\",test_images.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100 at 0x7FB3D034D050>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Test Images shape:\n",
            " (2305, 100, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxN5KnlefyEg"
      },
      "source": [
        "## Data Pre-processing on Test Data\n",
        "\n",
        "We reshape and normalize the test images similar to what we did in training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vFVPFxIeHn4"
      },
      "source": [
        "\n",
        "#Reshape test_images array to (length of test data,100,100,1) \n",
        "test_images=test_images.reshape(len(test_data),image_size,image_size,1)\n",
        "print(\"Test Images Shape: \\n\",test_images.shape)\n",
        "\n",
        "#Normalize image array\n",
        "test_images_scaled=test_images/255.0\n",
        "print(\"\\n Normalized/Scaled test images array \\n\",test_images_scaled[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYYzS6MlksDF"
      },
      "source": [
        "## Predict Test Data\n",
        "Time to predict test images using the model we trained. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efO4kq_TeAR2"
      },
      "source": [
        "#Predict Test labels\n",
        "predictions = model.predict(test_images_scaled)\n",
        "print(\"Predictions:\\n \",predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCJrgl_kfEMa"
      },
      "source": [
        "#Convert prediction probabilities to class labels\n",
        "output=np.asarray(np.zeros(len(test_data)),dtype='str')\n",
        "for i in range(len(test_data)):\n",
        "  output[i]=label_name[np.argmax(predictions[i])]\n",
        "\n",
        "print(\"Prediction labels of Test Data: \\n\",output[0:5])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12QbdzXSk6lY"
      },
      "source": [
        "## Save Predictions\n",
        "We now convert our predictions into a pandas dataframe and write it as \"submission.csv\" ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKRFJ_AugQJx"
      },
      "source": [
        "res = pd.DataFrame({'filename': test_labels['filename'], 'label': output})  # prediction is nothing but the final predictions of your model on input features of your new unseen test data\n",
        "res.to_csv(\"submission.csv\", index = False) \n",
        "\n",
        "# To download the csv file locally : Can skip this step in Jupyter\n",
        "from google.colab import files        \n",
        "files.download('submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}